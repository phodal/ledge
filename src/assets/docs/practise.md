# 闭环

## DevOps 生命周期

```process-table
| 需求 | 开发  | 构建  | 测试 | 部署 | 运维 |
|-|-|-|-|-|-|
| 把运维人员作为首要干系人 | 小团队 | 构建工具 | 自动化测试 | 部署工具 | 监控 |
| 在开发需求时寻找他们的意见 | 有限的合作 | 支持持续集成 | 用户验收测试|支持持续部署|对错误情况做出响应 |
| | 单元测试 | | | | 
```

```class
∞ 
```

## DevOps 四大支柱

来源：（《Effective DevOps》）

 - **协作**。协作是通过支持多人的交互和输入来构建一个特定结果的过程。
 - **亲密性**。不仅需要发展和维护个人之间的协作关系，还需要在组织内部、整个行业的团队和部分之间也需要建立紧密的关系。
 - **工具**。工具是一个加速器，可以基于当前的文化和方向推动变化。
 - **规模化**。规模化强调的是组织在整个生命周期中，所采用的过程和关键点。


# 价值流驱动

## 实例化需求

##

# 转型

## 人

来源：Scott Prugh 《[Continuous Delivery](https://www.scaledagileframework.com/guidance-continuous-delivery/)》

```process-step
 - I 型（专家）
   - 精通某个领域
   - 其它领域的技能或经验很少
   - 很快遇到瓶颈
   - 对下游的浪费和影响不敏感
   - 抵制灵活或者可变的计划
 - T 型（通才）
   - 精通某个领域
   - 拥有很多领域的技能
   - 能突破瓶颈
   - 帮助制订灵活和可变的计划
 - E 型
   - 精通某几个领域
   - 有多个领域的实践经验，执行能力强，能持续创新
   - 潜力无限
```

## 团队变革

## 组织变革

### 打造学习文化

在 ThoughtWorks 拥有这么一系列的培训（《[在ThoughtWorks我们如何做内部培训？](https://insights.thoughtworks.cn/how-we-do-training-in-thoughtworks/)》

 - ThoughtWorks 内部培训
   - ThoughtWorks University，面向毕业生
   - ThoughtWorks Immersion，面向社招
   - Session（分享，一个小时以内）
   - WorkShop（动手），如 OO BootCamp、Ruby BootCamp
   - ThoughtWorks 内训（原郑大晔校）
   - 组内培训
   - 社区

### 康威定律

# 加快流动

精益思想五大原则:

 - 价值（Value）
 - 价值流（Value stream）
 - 流动（Flow）
 - 拉动（Pull）
 - 尽善尽美（Perfection）

## 1. 持续集成

如《Jenkins 权威指南》一书指出，持续集成需要几个不同的阶段

 - 阶段一：无构建服务器
 - 阶段二：夜间构建
 - 阶段三：夜间构建 + 自动化测试
 - 阶段四：加入度量指标
 - 阶段五：更认真地对待测试
 - 阶段六：自动化验收测试和自动化部署
 - 阶段七：持续部署

### 持续集成基本纪律

 - 构建失败后，不要提交新的功能代码（仅限于修复）
 - 提交前，在本地运行所有的提交测试
 - 等持续集成测试通过后，再继续工作
 - 回家之前，构建必须处于成功状态（CI 红不过夜）
 - 时刻准备着回滚到前一个版本（CI Master）
 - 在回滚之前，要规定一个修复时间
 - 为自己导致的问题负责

### 通知

形式：

 - 电子邮件
 - RSS 订阅
 - 即时消息
 - IRC 通知
 - 桌面通知
 - 短信通知
 - 移动通知
 - 制造噪声
 - 极端反馈设备（如 CI 灯）

### 主干开发策略

基本原则：

1. 所有修改都要尽可能出现在主干上。
2. 每个分支都应该在使用后删除。
3. 主干分支的提交都应该保证持续可用。

## 2. 自动化

### 自动化演进路径

自动化演进路径（《SRE：Google 运维解密》）：

1. 没有自动化。手动将数据库主进程在多位个位置之间转移。
2. 外部维护的、系统特定的自动化系统。
3. 外部维护的、通用的自动化系统
4. 内部维护的、系统特定的自动化系统
5. 不需要任何的自动化系统

### 自动化部署

### 自动化部署策略

 - 全部部署
   - 蓝绿部署      
   - 滚动升级
 - 部分部署
   - 金丝雀测试
   - A / B 测试

### 自动化测试

见测试

### 自动化运维

如（《SRE：Google 运维解密》）一书中介绍的『服务可靠度层级模型』：

```pyramid
 - 服务可靠度层级模型
   - 产品设计
   - 软件开发
   - 容量规划
   - 测试 + 发布
   - 事后总结问题根源分析
   - 应急事件处理
   - 监控
```
## 3. 代码化

### 基础设施即代码

> 基础设施即代码是一种基于从软件开发实践的基础设施自动化的方法。它强调系统及其配置的日常置备和变更具有一致性和可重复性。 —— 《基础设施即代码：云服务器管理》

#### 原则

 - 系统能够被复制
 - 系统是用完可扔的
 - 系统是一致的
 - 过程是可重复的
 - 设计经常变更 

#### 实践

1. 使用定义文件（definition file)
2. 自文档化的系统和流程
3. 一切版本化
  - 可追溯性
  - 回滚
  - 相关性
  - 可见性
  - 可执行性
4. 持续测试系统和流程
5. 小的变更，而不是指变更  

### 流水线即代码

> 流水线即代码 (Pipeline as Code) 通过编码而非配置持续集成 / 持续交付 (CI/CD) 运行工具的方式定义部署流水线。

 - Jenkinsfile

Jenkinsfile 最佳实践（来源：《[Pipeline Best Practices](https://jenkins.io/doc/book/pipeline/pipeline-best-practices/)》

 1. 确保 Groovy 代码在流水线中只作为胶水。
 2. 避免流水线中的 Groovy 代码过于复杂
 3. 减少重复相似流水线的步骤
 4. 避免调用 ``Jenkins.getInstance``

使用共享库：

 1. 不要覆写内建的流水线步骤
 2. 避免巨大的全局变量声明文件
 3. 避免非常大的共享库

示例（来源《[流水线即代码](https://insights.thoughtworks.cn/pipeline-as-code/)》：

```groovy
node('master') {
   stage('Checkout') {…}
   stage('Code Analysis') {…}
   stage('Unit Test') {…}
   stage('Packing') {…}
   stage('Archive') {…}
   stage('DEV') {…}
}
stage('SIT') {
   timeout(time:4, unit:'HOURS') {
       input "Deploy to SIT?"
   }
   node('master') {…}
}
stage('Acceptance Test') {
   node('slave') {…}
}
```

### Deploy as Code

aka Deployment process as code

 - Dockerfile

### Docs like Code

> Docs like Code（文档代码化），是指采用开发软件的方式来开发文档，最后表现出文档和代码类似的现象。

它具备以下一些特征（《[软件技术文档代码化现象](https://zhuanlan.zhihu.com/p/33045831)》）

 1. **开发方式一致**。软件代码在开发的时候，基本流程是：写代码、审查代码和部署代码，文档在开发时候，也会采用和代码开发相同或类似的方式。
 2. **集成在开发流程中**。文档开发作为软件开发的一部分，也是最终产品的一部分，其开发过程是嵌入在整个软件开发过程中的。
 3. **开发工具一致**。文档写作时，一般使用代码编辑器如 Eclipse 或Visual Studio Code，而不会用诸如 Word 或 FrameMaker 这类工具。
 4. **使用标记语言**。一般使用轻量级标记语言如 Markdown, reStructuredText 或 ASCii 等，或更复杂的 XML 等标记语言。
 5. **文档和代码共同存储**。例如使用 Github，代码和文档会在同一个 repo 下，开发人员和文档工程师都可以访问。
 6. **版本控制**。一般使用 git 或 svn 这类工具进行版本管理。
 7. **网站发布自动化**。内容写作完成后，一拉 Web Hook 就能自动发布为帮助页面。

常见的实践有：

 - [ADR](https://www.phodal.com/blog/documenting-architecture-decisions/)（Architecture Decision Records，即架构决策记录）。是一个类似于亚历山大模式（即：设计模式）的短文本文件。（虽然决策本身不一定是模式，但它们分享着力量的特征平衡。）每个记录都描述了一组力量和一个响应这些力量的决策。请注意，决策是这里的核心部分，所以特定的力量可能出现在多个 ADR（架构决策记录） 中。

对应的系统实践：

 - 《[【架构拾集】基于 Markdown 文档展示系统设计](https://www.phodal.com/blog/architecture-in-realworld-markdown-based-document-system-design/)》

## 4. 实例化需求

# 缩短反馈

## 1. 测试

### 测试驱动开发

### TDD 三定律

 - **定律一** 在编写不能通过的单元测试前，不可编写生产代码
 - **定律二** 只可编写刚发无法通过的单元测试，不能编译也算不通过
 - **定律三** 只可编写刚好足以通过当前失败测试的生产代码

### 整洁的测试

如 Robert C. Martin 在《代码整洁之道》所说的那样，好的测试应该是：

 - 快速（Fast），测试应该够快。
 - 独立（Indendent），测试应该相互独立。
 - 可重复（Repeatable），测试应当可在任何环境中通过。
 - 自足验证（Self-Validating），测试应该有布尔值输出。
 - 及时（Timely），测试应该及时编写。

要我说的话，它应该还有：

 - **同一人编写**，测试应该由开发业务代码的编写。这样他/他们才知道自己代码写得烂。
 - **边界**，测试直接不影响业务代码。这里指的主要是 private -> public 的行为，又或者是业务代码中包含测试代码，而非因为测试对原有代码重构。
 - **有效命名**。测试信息应该体现在方法名上，表达某一个特定的需求。

测试代码应该遵循生产代码的质量标准。

## 2. 代码回顾

来源：《深入核心的敏捷开发》

```mindmap
 - 代码回顾（CodeReview)
   - 目的：学习 vs 挑错
   - 重点 
     - 代码 vs 作者
     - 习惯 vs bug
     - 模式 vs 反模式
   - 注意
     - 整洁代码 vs 我的写法
     - 整洁代码 vs 重新设计
   - 形式
     - 随机摄取代码（当天编写的）
     - 每日一次，每次半小时以内，每次回顾 200~300 行代码
```

PS：时间视真实的团队而定，如果不能每天进行代码回顾，时间一般控制在 0.5 ~ 1 小时内。

### 基本实践

 - 寻找一个适合多人回顾的显示器
 - 线下集中优先，远程次之
 - 制定回顾时间，及对应的回顾组织者（定期更换）
 - 先讲述用户故事（业务视角），再讲述实现视角
 - 当天代码，当天回顾
 - 未提交的代码不回顾（除非遇到问题）
 - 并非所有的代码都要回顾（根据需要）
 - 回顾时，随时记录修改的内容
 - 下次回顾时，需要检视上次的修改部分
 - 意见不统一时（小问题以规范为主），可以再次讨论（或是会议）
 - 功能过大时，可以考虑以小型 session / 专题的形式讲述

回顾的方式：

 - 由提交者，讲述编写的代码
 - 由其他/她人讲述提交者编写的代码

不能按时回顾时：

 - 改天，并拿出更多的时间
 - 积累过多未回顾代码时，Tech Lead 应当检视其他/她人写的代码 
## 3. 小步前进

> 小步前进是一系列步骤的集合，其目的是：集成越早问题越小。

### Git Hooks 

Git 钩子列表：

```bash
applypatch-msg     post-merge         pre-auto-gc        prepare-commit-msg
commit-msg         post-receive       pre-commit         push-to-checkout
post-applypatch    post-rewrite       pre-push           update
post-checkout      post-update        pre-rebase
post-commit        pre-applypatch     pre-receive
```

Commit Hook 示例：

```process-table
| 执行提交脚本 | 执行 pre-commit  | 执行 Checkstyle| 执行预置的 lint | 提交代码 |
|-|-|-|-|-|
| git-cz | husky | checkstyle | lint-staged | git commit |
| conventional-changelog| commitlint |  | | | 
| |  | | | |
```

Push Hook 示例：

```process
"git push" -> "执行 prePush" -> "执行 lint" -> "执行 testing" -> "提交"
```

提交信息规范（《[如何好一个 Git 提交信息及几种不同的规范](https://www.phodal.com/blog/how-to-write-a-better-git-commit-message/)》）：

 - **build**: 影响构建系统或外部依赖关系的更改（示例范围：gulp，broccoli，npm）
 - **ci**: 更改我们的持续集成文件和脚本（示例范围：Travis，Circle，BrowserStack，SauceLabs）
 - **docs**: 仅文档更改
 - **feat**: 一个新功能
 - **fix**: 修复错误
 - **perf**: 改进性能的代码更改
 - **refactor**: 代码更改，既不修复错误也不添加功能
 - **style**: 不影响代码含义的变化（空白，格式化，缺少分号等）
 - **test**: 添加缺失测试或更正现有测试

## 4. 高频率发布

## 5. 可视化

### 监控

### Dashborad

Dashing: http://dashing.io/

# 持续实验文化

## 持续学习

### 技术打磨

#### 练习入门

出自《[演进：在工作的前三年里快速成长（练习篇）](https://www.phodal.com/blog/evolution-how-to-practise/)》



#### 练习的进阶

诀窍（《[练习技术的诀窍](https://www.phodal.com/blog/how-to-make-practise-works/)》 

 - 可持续性：寻求量变
   - 让自己保持稳定的作息
   - 稳定的输出
   - 有充分的练习内容
 - 可度量
   - SMART
 - 可视化：产生仪式感
 - 小步前进
 - 里程碑：成就感

建议:

 - 从模仿开始
 - 时间限制的练习
 - 日常积累灵感
 - 用专业的工具

#### 高产

> 精通 one，学习 another，关注 next。 —— justjavac

高产策略（《[如何高产](https://www.phodal.com/blog/how-to-be-high-performance/)》

 - 制定时间、目标和产出策略
   - 长期目标，一个小目标
   - 时间投入收益比对
   - 知识沉淀：输出优于输入
   - 不造轮子，再造轮子
   - 技能图谱：寻找、练习、升华
 - 练习所需要的技能
 - 寻找合适的工具，并打磨工具和手艺
 - 练习速度、质量
 - 通过休息来提出产出

## 持续部署

发布工程哲学：

 - 自服务模型
 - 追求速度
 - 密闭性
 - 强调策略和流程

## 追求卓越

### 测试即文档

『单元测试是可执行的文档』

## 优化

### 童子军规则

> 提交的代码要比检出的更好

### 技术债务管理

技术债治理的四条原则（《[技术债治理的四条原则](https://insights.thoughtworks.cn/managing-technical-debt/)》）：

1. 核心领域优于其他子域
2. 可演进性优于可维护性
3. 明确清晰的责任定义优于松散无序的任务分配
4. 主动预防优于被动响应

# 工程实践

## 依赖管理

### 二进制管理 vs 源码依赖管理

| | 二进制依赖管理 | 源码依赖管理 |
|-|-|-|
|构建速度 |直接使用二进制文件，速度快| 所有代码全量构建，速度慢  |
|重构支持 |不能同时修改依赖的代码和项目自身的代码，重构困难 | 可以同时修改项目自身和依赖的代码，重构简单 |
|提交操作 |不同的代码仓库在不同的工作空间下分别提交代码，管理简单，效率较高 | 在同一个工作空间下管理多个仓库代码，代码修改分别提交到不同的仓库，容易出错 ，效率较低 |
|开发调度 |调度时无法跟踪到源码，即使发现依赖的问题，也无法修改 | 调试时可以看到源码，发布问题时也可以即时修改 |
|响应变化 |发布需求和问题时，需要寻找依赖提供方的帮助，并放在下一次的开发计划中 | 可以直接修改并马上应用 |

# 敏捷实践

## 极限编程实践

极限编程的价值观（《学习敏捷》）：

 - **沟通**。每个团队成员都清楚其他人在做什么。
 - **简化**。开发 保内尽量让写出的代码简单、直接。
 - **反馈**。不断进行测试和反馈，以保证产品的持量。
 - **勇气**。每个团队成员都应该专注于为项目作出更佳的选择，即使这意味着不得不抛弃失败的方案而从不同的角度去解决问题。
 - **尊重**。每个团队成对项目都是重要的、有价值的。

对应的实践整理如下：

 - 反馈
   - 测试驱动开发 
   - 计划游戏
   - 用户代表
   - 结对编程
 - 持续流程
   - 持续集成
   - 代码重构
   - 小的发布
 - 代码理解
   - 简单设计
   - 代码集体所有制
   - 编码标准
   - 系统隐喻
 - 工作环境
   - 每周 40 小时

### 结对编程

模式：

 - 领航员和驾驶员（Driver-Navigator）。键霸出没，请小心。
 - 乒乓模型。基于测试驱动开发的模式
 - 鼠标和键盘模式。

注意事项：

 1. 多沟通
 2. 确定开发任务列表
 3. 定期交换小伙伴
 4. 可持续的结对工作
 5. 多给新人机会
 6. 勇敢加勇敢
 7. 反馈
 8. 不是所有的场景都适合结对

# 测试

```quadrant
 - 测试四象限 （Brain Marick）
     - 自动/手动
       - 用户故事测试
       - 端到端测试
       - 回归测试
       - ……
     - 手动
       - 探索式测试
       - 用户验收测试
       - 用户演示（showcase）
       - 用户培训
       - 安全测试（业务部分）
       - ……
     - 自动化
       - 单元测试
       - 组件测试
       - 集成测试
       - ……
     - 工具
       - 安全测试（技术部分）
       - 性能测试
       - 辅助功能测试
       - ……

config: {"left": "支持团队", "right": "评价产品", "bottom": "面向技术", "top": "面向业务"}
```

## 测试金字塔

```pyramid
 - 测试金字塔
   - 集成测试
   - 组件测试
   - 单元测试
```

 - **单元测试**。
 - **集成测试**。
 - **系统测试**。

### 生产测试

又被称之为黑盒测试，包含了：

 - 黑盒测试
 - 压力测试
 - 金丝雀测试

## 测试驱动开发

依据 J.Timothy King 所总结的《[测试先行的12个好处](http://sd.jtimothyking.com/2006/07/11/twelve-benefits-of-writing-unit-tests-first/)》：

 - 测试可证明你的代码是可以解决问题的
 - 一面写单元测试，一面写实现代码，这样感觉更有兴趣
 - 单元测试也可以用于演示代码
 - 会让你在写代码之前做好计划
 - 它降低了 Bug 修复的成本
 - 可以得到一个底层模块的回归测试工具
 - 可以在不改变现有功能的基础上继续改进你的设计
 - 可以用于展示开发的进度
 - 它真实的为程序员消除了工作上的很多障碍
 - 单元测试也可以让你更好的设计
 - 单元测试比代码审查的效果还要好
 - 它比直接写代码的效率更高

详见：《[测试驱动开发](https://growth.phodal.com/#%E6%B5%8B%E8%AF%95%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91)》

## 测试策略

来源：《[一页纸测试策略](https://mp.weixin.qq.com/s/cEkI3Duyg-Jqk-TTFwKVqQ)》

> 质量内建，旨在软件交付过程的早期发现并预防缺陷，将任务移动到软件开发生命周期的左侧来提高质量，测试人员可以从需求分析阶段开始介入。

```process-table
| 需求分析 | 开发前 | 开发  | 开发完成 | 测试|  发布前|已发布 |
|--|--|--|--|--|--|--|
| 用户故事评审 | 特性启动 | 单元测试 | 用户故事验收 | 用户故事测试 | 回归测试 | 监控 |
| 估算 | 测试用例设计 | 组件测试 | 底层测试评审 | 探索式测试 | 发布指南 | 支持 |
| 方案设计 | 用户故事启动 | | 发布可测试版本 | 缺陷管理 | 用户验收测试 | 质量分析 |
| 迭代计划 | 测试计划 | | | 风险评估 | 发布版本确认 | | 
| | | | | 集成测试 | | | 
| | | | | 端到端测试 | | |  
```

## 自动化测试


### 三段式测试

 - BDD 方式（Given-When-Then）
 - 设置-操作-断言（Arrange-Act-Assert）
 
Given-When-Then表达方式可以称之为一个公式一个模板，这种方式旨在指导程序员为“用户故事”编写测试用例变得方便。

 - Given 一个上下文，指定测试预设
 - When 进行一系列操作，即所要执行的操作
 - Then 得到一系列可观察的后果，即需要检测的断言

E2E 定义示例：

```javascript
defineSupportCode(function({Given, When, Then}) {
    Given('当我在网站的首页', function() {
        return this.driver.get('http://0.0.0.0:7272/');
    });

    When('输入用户名 {string}', function (text) {
        return this.driver.findElement(By.id('username_field')).sendKeys(text)
    });

    When('输入密码 {string}', function (text) {
        return this.driver.findElement(By.id('password_field')).sendKeys(text)
    });

    When('提交登录信息', function () {
        return this.driver.findElement(By.id('login_button')).click()
    });

    Then('页面应该返回 {string}', function (string) {
      this.driver.getTitle().then(function(title) {
        expect(title).to.equal(string);
      });
    });
});
```

### 测试替身

> 有时候对被测系统(SUT)进行测试是很困难的，因为它依赖于其他无法在测试环境中使用的组件。这有可能是因为这些组件不可用，它们不会返回测试所需要的结果，或者执行它们会有不良副作用。在其他情况下，我们的测试策略要求对被测系统的内部行为有更多控制或更多可见性。 如果在编写测试时无法使用（或选择不使用）实际的依赖组件(DOC)，可以用测试替身来代替。测试替身不需要和真正的依赖组件有完全一样的的行为方式；他只需要提供和真正的组件同样的 API 即可，这样被测系统就会以为它是真正的组件！ ——Gerard Meszaros

Mock 和 Stub 就是常见的两种方式：

 - Stub 是一种状态确认，它用简单的行为来替换复杂的行为
 - Mock 是一种行为确认，它用于模拟其行为

示例见：《[测试替身](https://growth.phodal.com/#%E6%B5%8B%E8%AF%95%E6%9B%BF%E8%BA%AB)》

### 简单规则 

测试自动化应该遵循的简单规则

| 规则  | 理由 |
|-|-|
| 单一职责 | 易于调试：业务规则变更时易于修改 |
| 不要重复自己 | 能够只改一个地方 |
| 使用领域特定语言 | 使测试人员相关的沟通更加容易 |
| 抽象测试| 使测试更加易读 |
| 设置和清除（setup & teardown | 可以重复执行测试 |
| 避免访问数据库（尽可能）| 访问数据库会使测试变慢（注意，有些情况还是需要访问数据库的） |
| 测试必须一直保持绿色  | 保证测试的信心：活文档 |
| 应用公共测试标准（包括命名约定） | 可以共享代码或者测试的所有权，对测试达成共识 |
| 将测试（什么）和（如何）执行分隔 | 把什么（和为什么）抽象出来可以让各层分别完善；为使人读懂规则说明（测试），你可以增加更多示例，或者在不会影响精力规则的前提下更改底层自动化实现 |

## 测试代码坏味道

详见：《[测试代码的坏味道](https://www.phodal.com/blog/test-bad-smell/)》

> 测试代码坏味道，是指单元测试代码中的不良编程实践（例如，测试用例的组织方式，实现方式以及彼此之间的交互方式），它们表明测试源代码中潜在的设计问题。

常见的测试坏味道：

 - 空的测试。测试是生成的，但是没有内容。
 - 忽略的测试。即测试被 Ignore
 - 没有断言的测试。为了测试覆盖率而出现的测试
 - 多余的 Println。调试时留下的讯息。
 - 多重断言。每个测试函数只应该测试一个概念。

然后，再来个 Examples。

# 度量

## 评估与度量

#### 度量维度

 - 需求管理：平均需求交付时长
 - 开发管理：单元测试覆盖率、平均修复问题时间、问题打回率、代码注释率、代码质量
 - 构建管理：构建频率、平均构建时间、构建成功率
 - 部署管理：部署频率、平均部署时间、部署成功率
 - 进度管理：任务燃尽数

### 常见低效原因

如我司同事说：《[DevOps —— 实施DevOps应该考虑的若干问题](https://blog.csdn.net/gudufeiyang/article/details/104190250)》

 - **技术债务**：长期以来，开发团队只注重新功能的开发，不注意重构和流程改进，不注重新技术、新方法的运用。
 - **团队协作和流程**：传统的方式，开发团队和运维团队的工作是分离的。他们有不同考核和业务目标；工作过程中的协作方式基本依靠流程或电子流。
 - **系统架构不合理**：耦合度高，导致开发过程中的问题和领域不能被合理的分割，部署和运维过程也可能会导致整个系统崩溃。
 - **研发方法和流程不科学**：研发过程不够敏捷，或者敏捷过程中的重要实践并未正确的执行。
 - **人员技能偏低**：人员技能不足，无法支撑项目的架构设计、疑难技术的攻坚，无法满足业务的运维要求。
 - **团队文化**：没有形成良好的学习文化，在面对问题时指责、惩罚是重要手段，无法让所有成员坦诚的分析问题，无法从失败中学习技术和经验。

### 度量标准

#### 可用性度量

可用性度量公式：

> 网站可用性百分比 = （该期间的总秒数 - 系统宕机的秒数） / 该期间的总秒数

| 可用性 % | 每年的故障时间 | 每月的故障时间 | 每周的故障时间 | 每天的故障时间|
|-|-|-|-|-|
| 55.5555555% (9 个 5) | 162.33 天 | 13.53 天 | 74.92 小时 | 10.67 小时 |
| 90% (1 个 9) | 36.53 天 | 73.05 小时 | 16.80  小时 | 2.40 小时 |
| 95% (1.5 个 9) | 18.26 天 | 36.53 小时 | 8.40 小时 | 1.20 小时 |
| 97% | 10.96 天 | 21.92 小时 | 5.04 小时 | 43.20 分钟 |
| 98% | 7.31 天 | 14.61 小时 | 3.36 小时 | 28.80 分钟 |
| 99% (2 个 9) | 3.65 天 | 7.31 小时 | 1.68 小时 | 14.40 分钟 |
| 99.5% (2.5 个 9) | 1.83 天 | 3.65 小时 | 50.40 分钟 | 7.20 分钟 |
| 99.8% | 17.53 小时 | 87.66 分钟 | 20.16 分钟 | 2.88 分钟 |
| 99.9% (3 个 9) | 8.77 小时 | 43.83 分钟 | 10.08 分钟 | 1.44 分钟 |
| 99.95% (3.5 个 9) | 4.38 小时 | 21.92 分钟 | 5.04 分钟 | 43.20 秒 |
| 99.99% (4 个 9) | 52.60 分钟 | 4.38 分钟 | 1.01 分钟 | 8.64 秒 |
| 99.995% (4.5 个 9) | 26.30 分钟 | 2.19 分钟 | 30.24 秒 | 4.32 秒 |
| 99.999% (5 个 9) | 5.26 分钟 | 26.30 秒 | 6.05 秒 | 864.00 毫秒|
| 99.9999% (6 个 9) | 31.56 秒 | 2.63 秒 | 604.80 毫秒 | 86.40 毫秒 |
| 99.99999% (7 个 9) | 3.16 秒 | 262.98 毫秒 | 60.48 毫秒 | 8.64 毫秒 |
| 99.999999% (8 个 9) | 315.58 毫秒 | 26.30 毫秒 | 6.05 毫秒 | 864.00 微秒 |
| 99.9999999% (9 个 9) | 31.56 毫秒 | 2.63 毫秒 | 604.80 微秒 | 86.40 微秒 |

# 工具

## 选择工具

### BDD 工具选型

> Behavior Driven Development，行为驱动开发是一种敏捷软件开发的技术，它鼓励软件项目中的开发者、QA 和非技术人员或商业参与者之间的协作。

《[BDD 框架对比: Cucumber.js vs Robot Framework vs Gauge.js](https://github.com/phodal/bdd-frameworks-compare)》

考虑到情况有：

 - 团队水平
 - 语言因素。持续学习文化
 - 文档丰富度

## 制造工具

```process
"个人实践" -> "记录流程" -> "形成统一语言" -> "抽象原则与模式" -> "标准化流程（工具）"
```
